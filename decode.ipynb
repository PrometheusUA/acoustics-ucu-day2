{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment Decoding task from UCU Acoustic School"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given code\n",
    "\n",
    "From [here](https://gist.github.com/proger/a7e820fbfa0181273fdbf2351901d0d8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from g2p_en import G2p\n",
    "from tqdm import tqdm\n",
    "\n",
    "from praatio import textgrid as tgio\n",
    "from praatio.data_classes.interval_tier import Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frames(wav):\n",
    "    return torchaudio.compliance.kaldi.mfcc(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibriSpeech(torch.utils.data.Dataset):\n",
    "    def __init__(self, url=\"dev-clean\"):\n",
    "        super().__init__()\n",
    "        self.librispeech = torchaudio.datasets.LIBRISPEECH(\".\", url=url, download=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.librispeech)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        wav, sr, text, speaker_id, chapter_id, utterance_id = self.librispeech[index]\n",
    "        return make_frames(wav), text, (speaker_id, chapter_id, utterance_id) # returning additional ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=13, subsample_dim=128, hidden_dim=1024):\n",
    "        super().__init__()\n",
    "        self.subsample = nn.Conv1d(input_dim, subsample_dim, 5, stride=4, padding=3)\n",
    "        self.lstm = nn.LSTM(\n",
    "            subsample_dim, hidden_dim, batch_first=True, num_layers=3, dropout=0.2\n",
    "        )\n",
    "\n",
    "    def subsampled_lengths(self, input_lengths):\n",
    "        # https://github.com/vdumoulin/conv_arithmetic\n",
    "        p, k, s = (\n",
    "            self.subsample.padding[0],\n",
    "            self.subsample.kernel_size[0],\n",
    "            self.subsample.stride[0],\n",
    "        )\n",
    "        o = input_lengths + 2 * p - k\n",
    "        o = torch.floor(o / s + 1)\n",
    "        return o.int()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.subsample(x.mT).mT\n",
    "        x = x.relu()\n",
    "        x, _ = self.lstm(x)\n",
    "        return x.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.g2p = G2p()\n",
    "\n",
    "        # http://www.speech.cs.cmu.edu/cgi-bin/cmudict\n",
    "        self.rdictionary = [\"ε\", # CTC blank\n",
    "                            \" \",\n",
    "                            \"AA0\", \"AA1\", \"AE0\", \"AE1\", \"AH0\", \"AH1\", \"AO0\", \"AO1\", \"AW0\", \"AW1\", \"AY0\", \"AY1\",\n",
    "                            \"B\", \"CH\", \"D\", \"DH\",\n",
    "                            \"EH0\", \"EH1\", \"ER0\", \"ER1\", \"EY0\", \"EY1\",\n",
    "                            \"F\", \"G\", \"HH\",\n",
    "                            \"IH0\", \"IH1\", \"IY0\", \"IY1\",\n",
    "                            \"JH\", \"K\", \"L\", \"M\", \"N\", \"NG\",\n",
    "                            \"OW0\", \"OW1\", \"OY0\", \"OY1\",\n",
    "                            \"P\", \"R\", \"S\", \"SH\", \"T\", \"TH\",\n",
    "                            \"UH0\", \"UH1\", \"UW0\", \"UW1\",\n",
    "                            \"V\", \"W\", \"Y\", \"Z\", \"ZH\"]\n",
    "\n",
    "        self.dictionary = {c: i for i, c in enumerate(self.rdictionary)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rdictionary)\n",
    "\n",
    "    def encode(self, text):\n",
    "        labels = [c.replace('2', '0') for c in self.g2p(text) if c != \"'\"]\n",
    "        targets = torch.LongTensor([self.dictionary[phoneme] for phoneme in labels])\n",
    "        return targets\n",
    "\n",
    "    def decode(self, targets): # function to get symbol from token id\n",
    "        return [self.rdictionary[token] for token in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognizer(nn.Module):\n",
    "    def __init__(self, feat_dim=1024, vocab_size=55+1):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Linear(feat_dim, vocab_size)\n",
    "\n",
    "    def forward(self, features):\n",
    "        features = self.classifier(features)\n",
    "        return features.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()\n",
    "encoder = Encoder()\n",
    "recognizer = Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load('lstm_p3_360+500.pt', map_location='cpu')\n",
    "encoder.load_state_dict(ckpt['encoder'])\n",
    "recognizer.load_state_dict(ckpt['recognizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_frames, text, ids = LibriSpeech()[0]\n",
    "phonemes = vocab.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = encoder(audio_frames)\n",
    "outputs = recognizer.forward(features) # (T, 55+1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real phonemes:        MIH1STER0 KWIH1LTER0 IH1Z DHAH0 AH0PAA1SAH0L AH1V DHAH0 MIH1DAH0L KLAE1SAH0Z AH0ND WIY1 AA1R GLAE1D TUW1 WEH1LKAH0M HHIH1Z GAA1SPAH0L\n",
      "predicted phonemes:  εεεεεεεεεεεεεεεεεεεεMIH1STER0  KRIH1LTεεER0ε  εIH1Z DHAH0  AH0εPPεAA1SεAH0AH0LL  AH1V DHAH0 MIH1DAH0LL KLεAE1εSεAH0AH0εZεε  εAH0ND WIH1εRR GLLεAE1DDε TTWWWEH1LKKεAH0M   HHIH1Zε  GεAA1SSPPεAH0Lεεεεεεεε\n"
     ]
    }
   ],
   "source": [
    "print('real phonemes:       ', ''.join(vocab.decode(phonemes)))\n",
    "print(f'predicted phonemes: ', ''.join(vocab.decode(torch.argmax(outputs, dim=1))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample output size vs sample audio size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 584)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size()[0], audio_frames.size()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to segment all audio frames and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2703 [00:04<54:46,  1.22s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17204/1357056485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maudio_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLibriSpeech\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17204/1823090261.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    814\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "utt_i=0\n",
    "for audio_frames, text, ids in tqdm(LibriSpeech()):\n",
    "    # try:\n",
    "    features = encoder(audio_frames)\n",
    "    outputs = recognizer.forward(features)\n",
    "\n",
    "    tg = tgio.Textgrid()\n",
    "    tg.minTimestamp = 0\n",
    "    tg.maxTimestamp = audio_frames.size()[0] / 100\n",
    "\n",
    "    tier_name = 'phones'\n",
    "    phones_tier = tgio.IntervalTier(tier_name, [], minT=0, maxT=tg.maxTimestamp)\n",
    "\n",
    "    intervals = []\n",
    "    output_tokens = torch.argmax(outputs, dim=1)\n",
    "    decoded_output_tokens = vocab.decode(output_tokens)\n",
    "    prev_token, prev_start = None, 0\n",
    "\n",
    "    for i, token in enumerate(decoded_output_tokens):\n",
    "        # print(f'{i}: {token=}, {prev_token=}, {prev_start=};')\n",
    "        if prev_token != token and prev_token:\n",
    "            intervals.append(Interval(prev_start, i/25, prev_token))\n",
    "            prev_token = token\n",
    "            prev_start = i/25\n",
    "        elif not prev_token:\n",
    "            prev_token = token\n",
    "    if prev_token:\n",
    "        intervals.append(Interval(prev_start, tg.maxTimestamp, prev_token))\n",
    "\n",
    "    new_phonemes_tier = phones_tier.new(entries=intervals)\n",
    "    tg.addTier(new_phonemes_tier)\n",
    "\n",
    "    tg.save(f'{output_dir}/{ids[0]}_{ids[1]}_{ids[2]}.TextGrid',\n",
    "            includeBlankSpaces=True,\n",
    "            format='long_textgrid',\n",
    "            reportingMode='error')\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    #     print(utt_i, ids)\n",
    "    utt_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
